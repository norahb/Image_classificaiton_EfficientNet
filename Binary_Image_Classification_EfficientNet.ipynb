{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3gypL94TcjJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihd8Yxa_T47U"
      },
      "outputs": [],
      "source": [
        "# Define the input shape and number of classes\n",
        "img_width, img_height = 260, 260  # Default image size for EfficientNetV2-S\n",
        "num_classes = 2\n",
        "train_dir = 'dataset_path/train'\n",
        "val_dir = 'dataset_path/val'\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmL5fAIZaRAf"
      },
      "outputs": [],
      "source": [
        "# Add forms to allow users to choose different image sizes and epochs\n",
        "img_width = input(\"Enter the image width (e.g., 224): \")  # Ask the user to input the image width\n",
        "img_height = input(\"Enter the image height (e.g., 224): \")  # Ask the user to input the image height\n",
        "img_width, img_height = int(img_width), int(img_height)  # Convert inputs to integers\n",
        "\n",
        "epochs = int(input(\"Enter the number of epochs (e.g., 10): \"))  # Ask the user to input the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ObDesvwT83i"
      },
      "outputs": [],
      "source": [
        "# Create the data generators for training and validation sets\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_width, img_height), batch_size=32, class_mode='binary')\n",
        "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(img_width, img_height), batch_size=32, class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig40h-g7aRA8"
      },
      "outputs": [],
      "source": [
        "effnet_version = input(\"Enter the EfficientNetV2 version (e.g., EfficientNetV2S, EfficientNetV2M, etc.): \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6UYQ-DWaRA9"
      },
      "outputs": [],
      "source": [
        "# Load the specified EfficientNetV2 model version\n",
        "if effnet_version in [\"EfficientNetV2B0\", \"EfficientNetV2B1\", \"EfficientNetV2B2\", \"EfficientNetV2B3\", \"EfficientNetV2S\", \"EfficientNetV2M\", \"EfficientNetV2L\"]:\n",
        "    base_model = tf.keras.applications.__getattribute__(effnet_version)(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "else:\n",
        "    print(\"Invalid EfficientNetV2 version. Please choose from the provided options.\")\n",
        "    exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drDenhIvWNwu"
      },
      "outputs": [],
      "source": [
        "# Add custom top layers for your specific task\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "682wgbmiWJYq"
      },
      "outputs": [],
      "source": [
        "# Freeze the pre-trained layers except the top layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn0QU3tVT6hS"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzGaKWbNUC__"
      },
      "outputs": [],
      "source": [
        "# Compile the model with your specific loss function and optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qf1kuAD6T7G3"
      },
      "outputs": [],
      "source": [
        "# Train the model with your\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-GKN--7ZBB6"
      },
      "outputs": [],
      "source": [
        "val_acc = history.history['val_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Uiu6C3FpED"
      },
      "outputs": [],
      "source": [
        "# Visulaize training results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OujtCthwaRBa"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save(\"saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO9zju9KaRBm"
      },
      "outputs": [],
      "source": [
        "# Test the model on a new image\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smUfA-G3aRCB"
      },
      "outputs": [],
      "source": [
        "# load new image\n",
        "new_image_path = \"path_to_new_image.jpg\"\n",
        "img = image.load_img(new_image_path, target_size=(img_width, img_height))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ5pkMJPaRCK"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "saved_model = tf.keras.models.load_model(\"saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyZPNsqHaRCL"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "predictions = saved_model.predict(img_array)\n",
        "predicted_class = \"Class1\" if predictions[0][0] < 0.5 else \"Class2\"\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}